{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import bz2\n",
    "import csv\n",
    "import json\n",
    "import bisect\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ancestor(ancestors, samples, graph):\n",
    "    for s in samples:\n",
    "        for n, v in graph[s]:\n",
    "            if n not in ancestors:\n",
    "                ancestors.add(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_layer_nodes(graph, layer_dict, post_size, layer_sample=5, initial_samples=None):\n",
    "    chosen = set()\n",
    "    ancestors = set()\n",
    "    if initial_samples:\n",
    "        for s in initial_samples:\n",
    "            chosen.add(s)\n",
    "        add_ancestor(ancestors, chosen, graph)\n",
    "    yset = list(layer_dict.keys())\n",
    "    yset.sort(reverse=True)\n",
    "    max_y = max(yset)\n",
    "    print('ancestor: ',ancestors)\n",
    "    for y in yset:\n",
    "        print('layer : ', y)\n",
    "        if y == max_y:\n",
    "            candidates = [(post_size[s], s) for s in layer_dict[y]]\n",
    "        else:\n",
    "            candidates = [(post_size[s], s) for s in layer_dict[y] if s in ancestors]\n",
    "        if len(candidates) == 0:\n",
    "            print(y)\n",
    "            continue\n",
    "        candidates.sort(reverse=True)\n",
    "        print(len(candidates))\n",
    "        candidates = candidates[:50]\n",
    "        probs = np.array([v[0] for v in candidates])\n",
    "        probs = probs / np.sum(probs)\n",
    "        count = sum([1 if s in chosen else 0 for s in layer_dict[y]])\n",
    "        if layer_sample > count:\n",
    "            samples = np.random.choice([v[1] for v in candidates],\n",
    "                                       size=layer_sample - count, replace=False, p=probs)\n",
    "            chosen |= set(samples)\n",
    "            add_ancestor(ancestors, samples, graph)\n",
    "    return chosen, ancestors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gadgets', 0.04),\n",
       " ('gaming', 0.07),\n",
       " ('entertainment', 0.1),\n",
       " ('business', 0.11),\n",
       " ('science', 0.12),\n",
       " ('programming', 0.15),\n",
       " ('politics', 0.22),\n",
       " ('reddit.com', 0.56)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['AskReddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ancestor:  set()\n",
      "layer :  10\n",
      "84\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'gameflysocial'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f73c000add86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchosen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancestors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_layer_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_size_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-971fc45da30d>\u001b[0m in \u001b[0;36msample_layer_nodes\u001b[0;34m(graph, layer_dict, post_size, layer_sample, initial_samples)\u001b[0m\n\u001b[1;32m     29\u001b[0m                                        size=layer_sample - count, replace=False, p=probs)\n\u001b[1;32m     30\u001b[0m             \u001b[0mchosen\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0madd_ancestor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancestors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchosen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancestors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-45f3f4f23183>\u001b[0m in \u001b[0;36madd_ancestor\u001b[0;34m(ancestors, samples, graph)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_ancestor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mancestors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mancestors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mancestors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gameflysocial'"
     ]
    }
   ],
   "source": [
    "chosen, ancestors = sample_layer_nodes(graph, reverse_dict, post_size_dict, layer_sample=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = pd.read_json('submissions_creator_common_graph_100',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile['weight'] = datafile['common'].apply(lambda x : len(x)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common</th>\n",
       "      <th>s1</th>\n",
       "      <th>s1_start</th>\n",
       "      <th>s2</th>\n",
       "      <th>s2_start</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1328730</th>\n",
       "      <td>[antdude]</td>\n",
       "      <td>illusions</td>\n",
       "      <td>1314054230</td>\n",
       "      <td>ShiaLabeouf</td>\n",
       "      <td>1357410751</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722416</th>\n",
       "      <td>[RightWingersSuck]</td>\n",
       "      <td>DenverBroncos</td>\n",
       "      <td>1286580415</td>\n",
       "      <td>TrueProgressive</td>\n",
       "      <td>1376151471</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722417</th>\n",
       "      <td>[99red]</td>\n",
       "      <td>Barca</td>\n",
       "      <td>1286885132</td>\n",
       "      <td>TrueProgressive</td>\n",
       "      <td>1376151471</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722418</th>\n",
       "      <td>[Aschebescher]</td>\n",
       "      <td>thrashmetal</td>\n",
       "      <td>1289197100</td>\n",
       "      <td>TrueProgressive</td>\n",
       "      <td>1376151471</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722419</th>\n",
       "      <td>[PinkSlimeIsPeople]</td>\n",
       "      <td>moderatepolitics</td>\n",
       "      <td>1289327856</td>\n",
       "      <td>TrueProgressive</td>\n",
       "      <td>1376151471</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      common                s1    s1_start               s2  \\\n",
       "1328730            [antdude]         illusions  1314054230      ShiaLabeouf   \n",
       "1722416   [RightWingersSuck]     DenverBroncos  1286580415  TrueProgressive   \n",
       "1722417              [99red]             Barca  1286885132  TrueProgressive   \n",
       "1722418       [Aschebescher]       thrashmetal  1289197100  TrueProgressive   \n",
       "1722419  [PinkSlimeIsPeople]  moderatepolitics  1289327856  TrueProgressive   \n",
       "\n",
       "           s2_start  weight  \n",
       "1328730  1357410751    0.01  \n",
       "1722416  1376151471    0.01  \n",
       "1722417  1376151471    0.01  \n",
       "1722418  1376151471    0.01  \n",
       "1722419  1376151471    0.01  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile = datafile.sort_values(['weight'])\n",
    "datafile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile['weight'] = datafile.common.apply(lambda x : len(x)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2657461\n",
      "90317\n"
     ]
    }
   ],
   "source": [
    "print(len(datafile))\n",
    "datafile_query = datafile.query('weight>=0.04')\n",
    "print(len(datafile_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datafile_query.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_d3 = datafile_query[[\"s2\",\"s1\",'weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {}\n",
    "for i in csv_d3.values:\n",
    "    if(i[0] in graph):\n",
    "        temp = graph[i[0]]\n",
    "        temp.append((i[1],i[2]))\n",
    "        graph[i[0]] = temp\n",
    "    else:\n",
    "        graph[i[0]] = [(i[1],i[2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19616"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = pd.read_csv('./community_graph/layer_year.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_size = pd.read_csv('./community_graph/size.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>science</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      subreddit  layer\n",
       "0           0      worldnews      1\n",
       "1           1     reddit.com      0\n",
       "2           2       politics      0\n",
       "3           3        science      0\n",
       "4           4  entertainment      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_size_dict = {}\n",
    "for i in post_size.values:\n",
    "    post_size_dict[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict_1 = {}\n",
    "for i in layer.values:\n",
    "    layer_dict_1[i[1]] = i[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_dict = {}\n",
    "for k in layer_dict_1:\n",
    "    v = layer_dict_1[k]\n",
    "    if v not in reverse_dict:\n",
    "        reverse_dict[v] = []\n",
    "    reverse_dict[v].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 30215, 713734)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reverse_dict),len(layer_dict_1),len(post_size_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "7610",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-f73c000add86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchosen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancestors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_layer_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_size_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-93ce53b57439>\u001b[0m in \u001b[0;36msample_layer_nodes\u001b[0;34m(graph, layer_dict, post_size, layer_sample, initial_samples)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mancestors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-93ce53b57439>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mancestors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 7610"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_d3 = csv_d3.rename(index=str, columns={\"s2\": \"child\", \"s1\": \"parent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90317"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv_d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_d3.columns= ['id','parent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_d3.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4875"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv_d3.parent.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4875\n"
     ]
    }
   ],
   "source": [
    "parent_child = {}\n",
    "for i in csv_d3.values:\n",
    "    parent = i[1]\n",
    "    child = i[0]\n",
    "    if parent in parent_child:\n",
    "        temp = parent_child[parent]\n",
    "        temp.append(child)\n",
    "        parent_child[parent] = temp\n",
    "    else:\n",
    "        parent_child[parent] = [child]\n",
    "\n",
    "print(len(parent_child))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4647"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parent_child['reddit.com'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3994\n"
     ]
    }
   ],
   "source": [
    "graph = {}\n",
    "nodes = set()\n",
    "nodes.add('reddit.com')\n",
    "while len(nodes) !=0:\n",
    "    curr = nodes.pop()\n",
    "    if(curr in parent_child):\n",
    "        nodes |= set(parent_child[curr])\n",
    "        graph[curr] = parent_child[curr]\n",
    "print(len(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "graph_json = json.dumps(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_all = open('d3-new-15-all.csv','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "child = set()\n",
    "for i in graph:\n",
    "    for j in graph[i]:\n",
    "        if j not in child:\n",
    "            child.add(j)\n",
    "        else:\n",
    "            csv_all.write(j+','+i+'\\n')\n",
    "csv_all.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = set()\n",
    "for i in graph:\n",
    "    n.add(i)\n",
    "    for j in graph[i]:\n",
    "            n.add(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18854\n"
     ]
    }
   ],
   "source": [
    "child = set()\n",
    "child_1 = set()\n",
    "for i in graph:\n",
    "    for j in graph[i]:\n",
    "        if j not in child:\n",
    "            child.add(j)\n",
    "        else:\n",
    "            child_1.add(j)\n",
    "print(len(set(list(child_1)+list(child))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18855"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "parents = np.setdiff1d(csv_d3.parent.unique(),csv_d3.child.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = ['root' for i in parents]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = {'child': parents, 'parent':root}\n",
    "temp = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d3 = temp.append(csv_d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d3.drop_duplicates('child',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d3.to_csv(\"d3-noduplicates.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_d3.to_csv(\"d3.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = datafile_query.s1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(len(source))\n",
    "print(len(datafile_query.s2.unique()))\n",
    "len(np.intersect1d(source,datafile_query.s2.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_val = {}\n",
    "for row in source[7:]:\n",
    "    children= datafile_query.query('s1==\\''+str(row)+'\\'')['s2'].values\n",
    "    child = [dict(name=pn) for pn in children]\n",
    "    json_val[\"name\"] = row\n",
    "    json_val[\"children\"] = child\n",
    "    print(json.dumps(json_val))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['nodes'] = []\n",
    "data['links'] = []\n",
    "names = []\n",
    "\n",
    "for row in datafile_query.values:\n",
    "\ts1 = row[1]\n",
    "\ts2 = row[3]\n",
    "\tweight = row[-1]\n",
    "\tif not s1  in names:\n",
    "\t\tnode1 = {}\n",
    "\t\tnode1['id'] = s1\n",
    "\t\tnode1['group'] = row[2]\n",
    "\t\tnames.append(s1)\n",
    "\t\tdata['nodes'].append(node1)\n",
    "\tif not s2  in names:\n",
    "\t\tnode2 = {}\n",
    "\t\tnode2['id'] = s2\n",
    "\t\tnode2['group'] = row[4]\n",
    "\t\tnames.append(s2)\n",
    "\t\tdata['nodes'].append(node2)\n",
    "\tlink = {}\n",
    "\tlink['source'] = s1\n",
    "\tlink['target'] = s2\n",
    "\tlink['value'] = weight\n",
    "\tdata['links'].append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(data['nodes']),len(data['links']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('sample_graph.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['links'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
